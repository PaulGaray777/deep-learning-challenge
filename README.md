# deep-learning-challenge
## Overview:
Alphabet Soup organization is looking forward to having a tool that helps them select the applicants for funding with the best chance of success in their ventures. To give a solution, the proposal is a machine learning, specifically a neural network model ( which is inspired by the structure and functioning of the human brain). Basically, this is an artificial intelligence algorithm that can learn from data and make predictions for the input data. The given dataset is a CSV containing more than 34,000 organizations that have received funding from Alphabet Soup over the years.

## Data Preprocessing:
Target variable: The target variable of this project was “IS_SUCCESSFUL". This column dictates if funding application was successful or not.
Feature variables: "APPLICATION_TYPE", "AFFILIATION", "CLASSIFICATION", "USE_CASE", "ORGANIZATION", "STATUS", "INCOME_AMT", "SPECIAL_CONSIDERATIONS" and "ASK_AMT", except for: "NAME" and "EIN" which are identification and not wanted data for training our model.

## Compiling, Training, and Evaluating the Model:
The model used in this project was designed as a sequential neural network with two hidden layers. These hidden layers were configured with different combinations of neurons and utilized the "relu" activation function. The first configuration had 20 neurons in both hidden layers, the second had 70 neurons in the first hidden layer and 30 neurons in the second hidden layer, and the third configuration had 50 neurons in both hidden layers. The output layer of the model employed the "sigmoid" activation function. In the efforts to optimize the model's performance I try experimenting with different numbers of neurons in the hidden layers and considering additional hidden layers. Also, I consider removing unnecessary variables (columns) that may affect the model´s training. The achieved accuracy was 72.6% (Accuracy: 0.7259474992752075; Loss: 0.558203935623169).  
 
## Summary:
The deep learning model developed for Alphabet Soup showed promising results in predicting the success of funding applications. Despite the implementation of various optimization techniques, such as adjusting and experimenting with different combinations of neurons and activation functions for the layers, the expected performance was not reach. The final model achieved an accuracy of 72.6% (Accuracy: 0.7259474992752075; Loss: 0.558203935623169), which, although acceptable, fell short for the objective of 75%. As part of the development process, we performed data cleansing and employed binning techniques to improve the model's training. The model is not yet a fully matured machine learning algorithm. It still has it´s limitations and has not reached its full potential to deliver the expected accuracy. It is important to make an emphasis that more development is necessary before considering the model as a reliable tool for selecting applicants for funding. In such cases, alternative methods and parameters should be explored to obtain more favorable outputs. Recognizing that the model does provide valuable insights into what influence funding success.  The model can eventually achieve a higher level of accuracy and become a powerful tool in the field of funding application assessment.
